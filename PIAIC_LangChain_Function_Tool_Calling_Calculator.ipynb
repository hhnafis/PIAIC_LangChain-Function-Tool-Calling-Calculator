{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT4wKt74DoBi0v3h3U0E6t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hhnafis/PIAIC_LangChain-Function-Tool-Calling-Calculator/blob/main/PIAIC_LangChain_Function_Tool_Calling_Calculator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQTBi12dA9vV",
        "outputId": "3f2cdb1b-42d5-41d1-8e04-e17a1cb9ec3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#Install dependencies\n",
        "!pip install -Uq langchain langchain-google-genai python-dotenv langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading API key\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "GOOGLE_GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "9rj9YWgCDkx8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining calculator tool with optional enhancements\n",
        "import math\n",
        "\n",
        "class Calculator:\n",
        "    def calculate(self, expression: str) -> str:\n",
        "      try:\n",
        "        if any(func in expression.lower() for func in ['log', 'sin', 'cos', 'tan', 'sqrt']):\n",
        "\n",
        "          #Handle logrithmic problems\n",
        "          if 'log' in expression.lower():\n",
        "            try:\n",
        "              base,num = map(float(expression.lower().replace('log', '').split('')))\n",
        "              result = math.log(num, base)\n",
        "              return str(result)\n",
        "            except:\n",
        "              try:\n",
        "                num = float(expression.lower().replace('log','').split(''))\n",
        "                result = math.log10(num)\n",
        "                return str(result)\n",
        "              except ValueError as e:\n",
        "                return f\"Error: {e}. Invalid logarithm input\"\n",
        "\n",
        "            #Handle trignometery problems\n",
        "          elif 'sin' in expression.lower():\n",
        "            angle = float(expression.lower().replace('sin','').split(''))\n",
        "            result = math.sin(math.radians(angle))\n",
        "            return str(result)\n",
        "          elif 'cos' in expression.lower():\n",
        "            angle = float(expression.lower().replace('cos','').split(''))\n",
        "            result = math.cos(math.radians(angle))\n",
        "            return str(result)\n",
        "          elif 'tan' in expression.lower():\n",
        "            angle = float(expression.lower().replace('tan','').split(''))\n",
        "            result = math.tan(math.radians(angle))\n",
        "            return str(result)\n",
        "          elif 'sqrt' in expression.lower():\n",
        "            num = float(expression.lower().replace('sqrt','').split(''))\n",
        "            result = math.sqrt(num)\n",
        "            return str(result)\n",
        "          else:\n",
        "            return \"Invalid trigonometric function\"\n",
        "        else:\n",
        "\n",
        "          #Handle simple arithmatic problems found in the expression\n",
        "          result = eval(expression, {'__builtins__':None},{})\n",
        "          return str(result)\n",
        "      except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wieNjZkDDpgd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Created the Tool Wrapper for LangChain\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def calculator(expression:str) -> str:\n",
        "  \"\"\"\n",
        "  Perform mathematical calculations.\n",
        "  Input: A mathematical expression as a string (e.g., \"2 + 2\")\n",
        "  Output: Result of the calculation as a string. \"\"\"\n",
        "\n",
        "  calc = Calculator()\n",
        "  return calc.calculate(expression)"
      ],
      "metadata": {
        "id": "8rJUHoIIDw-k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seting Up the Google Gemini Flash Model\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_GEMINI_API_KEY= userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Initializing the Gemini model\n",
        "gemini_model = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\",api_key=GOOGLE_GEMINI_API_KEY)\n"
      ],
      "metadata": {
        "id": "eJdGfyD5D2gM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing LLM with tool-calling capabilities.\n",
        "\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents import AgentExecutor\n",
        "tools = [calculator]\n",
        "\n",
        "# Initializing the agent with tool-calling capabilities\n",
        "agent = initialize_agent(\n",
        "    tools, gemini_model, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")\n",
        "\n",
        "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oztXImJrD8tc",
        "outputId": "08cb281f-98c5-4e36-b343-389ca64de43a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2570a2cdc807>:9: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain --upgrade #Upgraded langchain to the newest version\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Seting up memory to maintain conversation context\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Defining a prompt template that incorporates the conversation history\n",
        "template = \"\"\"You are a helpful assistant having a conversation with a user.\n",
        "Current Conversation:\n",
        "{history}\n",
        "Human: {human_input}\n",
        "Assistant:\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"human_input\"], template=template\n",
        ")\n",
        "\n",
        "# Build ingthe LLMChain\n",
        "llm_chain = LLMChain(llm=gemini_model, prompt=prompt, memory=memory)\n",
        "\n",
        "# Function to interact with the chain and agent\n",
        "def conversational_agent(user_input):\n",
        "  # Get LLM response considering conversation history\n",
        "  llm_response = llm_chain.run(human_input=user_input)\n",
        "\n",
        "  # If the response suggests using a tool, call the agent\n",
        "  if \"calculator\" in llm_response.lower():\n",
        "    agent_response = executor.invoke(llm_response)  # Use executor for tool calls\n",
        "    return agent_response\n",
        "  else:\n",
        "    return llm_response\n",
        "\n"
      ],
      "metadata": {
        "id": "O9_rxPhkEBIi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple queries\n",
        "queries = [\n",
        "    \"What is 25 multiplied by 4?\",\n",
        "    \"Now divide the result by 5.\",\n",
        "    \"Add 10 to that.\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(\"Query:\", q)\n",
        "    print(\"Response:\", conversational_agent(q))\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAHgeFG6EFE2",
        "outputId": "723e3b41-f44c-47fe-8a52-77d187586e90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is 25 multiplied by 4?\n",
            "Response: 25 multiplied by 4 is 100.\n",
            "----------------------------------------\n",
            "Query: Now divide the result by 5.\n",
            "Response: 100 divided by 5 is 20.\n",
            "----------------------------------------\n",
            "Query: Add 10 to that.\n",
            "Response: Adding 10 to 20 gives you 30.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optional enhancement\n",
        "\n",
        "queries = [\n",
        "    \"Calculate the log of 100 to the base 10.\",\n",
        "    \"What is the square root of 64?\",\n",
        "    \"Find the tangent of 45 degrees.\",\n",
        "    \"Find the cosine of 30 degrees.\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(\"Query:\", q)\n",
        "    print(\"Response:\", conversational_agent(q))\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwi0cw4XEMN0",
        "outputId": "192074e7-7b17-465e-9d5e-2d1455a279d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Calculate the log of 100 to the base 10.\n",
            "Response: The logarithm of 100 to the base 10 is 2.  (Because 10 to the power of 2 equals 100).\n",
            "----------------------------------------\n",
            "Query: What is the square root of 64?\n",
            "Response: The square root of 64 is 8.\n",
            "----------------------------------------\n",
            "Query: Find the tangent of 45 degrees.\n",
            "Response: The tangent of 45 degrees is 1.\n",
            "----------------------------------------\n",
            "Query: Find the cosine of 30 degrees.\n",
            "Response: The cosine of 30 degrees is √3/2  or approximately 0.866.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversational_agent(\"What are the calculations, I asked uptill here?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCRSKUwyEP1U",
        "outputId": "e00324d3-d599-4ba3-dea7-81b81bf8920d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a summary of the calculations we performed:\n",
            "\n",
            "1. **Multiplication:** 25 * 4 = 100\n",
            "2. **Division:** 100 / 5 = 20\n",
            "3. **Addition:** 20 + 10 = 30\n",
            "4. **Logarithm:** log₁₀(100) = 2\n",
            "5. **Square Root:** √64 = 8\n",
            "6. **Trigonometry:** tan(45°) = 1\n",
            "7. **Trigonometry:** cos(30°) = √3/2 ≈ 0.866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#End"
      ],
      "metadata": {
        "id": "fJRp9aMkEYa-"
      }
    }
  ]
}